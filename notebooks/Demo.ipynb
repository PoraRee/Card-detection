{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb22532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp311-none-macosx_10_9_x86_64.whl (143.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp311-cp311-macosx_10_9_x86_64.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.0.2-cp311-cp311-macosx_10_9_x86_64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/nattamon/opt/anaconda3/envs/chulacv2022/lib/python3.11/site-packages (from torch) (4.4.0)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /Users/nattamon/opt/anaconda3/envs/chulacv2022/lib/python3.11/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/nattamon/opt/anaconda3/envs/chulacv2022/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in /Users/nattamon/opt/anaconda3/envs/chulacv2022/lib/python3.11/site-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: requests in /Users/nattamon/opt/anaconda3/envs/chulacv2022/lib/python3.11/site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/nattamon/opt/anaconda3/envs/chulacv2022/lib/python3.11/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nattamon/opt/anaconda3/envs/chulacv2022/lib/python3.11/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nattamon/opt/anaconda3/envs/chulacv2022/lib/python3.11/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nattamon/opt/anaconda3/envs/chulacv2022/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nattamon/opt/anaconda3/envs/chulacv2022/lib/python3.11/site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nattamon/opt/anaconda3/envs/chulacv2022/lib/python3.11/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, filelock, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.12.0 mpmath-1.3.0 sympy-1.12 torch-2.0.1 torchaudio-2.0.2 torchvision-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe874346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from module.Segmentor import Segmentor\n",
    "from module.Classifier import Classifier\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../assets/test.mp4'\n",
    "\n",
    "inputStream = cv2.VideoCapture(filename)\n",
    "\n",
    "FPS = int(24)\n",
    "inputWidth = int(inputStream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "inputHeight = int(inputStream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "outputStream = cv2.VideoWriter('../assets/test-results.mp4',\n",
    "                               cv2.VideoWriter_fourcc('x', '2', '6', '4'),\n",
    "                               FPS, (inputWidth, inputHeight))\n",
    "\n",
    "while inputStream.isOpened():\n",
    "    ret, frame = inputStream.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"End of stream? Exiting...\")\n",
    "        break\n",
    "        \n",
    "    segmentor = Segmentor(\n",
    "        min_p=4,\n",
    "        max_p=400,\n",
    "        min_a=1000,\n",
    "        max_a=20000,\n",
    "        suit_x_ratio=2 / 7,\n",
    "        suit_y_ratio=1 / 5,\n",
    "    )\n",
    "    \n",
    "    classifer = Classifier()\n",
    "    \n",
    "    st = time.time()\n",
    "    results = segmentor.seg(frame)\n",
    "    en = time.time()\n",
    "    print(\"time:\", en - st)\n",
    "    \n",
    "    print(len(results))\n",
    "\n",
    "    frameMarked = frame.copy()\n",
    "    for result in results:\n",
    "        contour = np.array(result['bbox'])\n",
    "        cv2.drawContours(frameMarked, [contour], 0, (0, 0, 255), 3)\n",
    "        card_class = classifer.get_class(result['suit'])\n",
    "        cv2.putText(frameMarked, card_class, [contour[0]], cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0, 0, 255))\n",
    "    \n",
    "    # Encode image as jpg numpy array\n",
    "    _, buf = cv2.imencode(\".jpg\", frameMarked)\n",
    "    # Draw result\n",
    "    IPython.display.display(IPython.display.Image(data=buf))\n",
    "    outputStream.write(frameMarked)\n",
    "        \n",
    "    clear_output(wait=True) \n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "outputStream.release()\n",
    "inputStream.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab9f26f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf002350",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hey\")\n",
    "filename = '../bicyclecard/images/IMG_20230520_185700449.jpg'\n",
    "inputImage = cv2.imread(filename)\n",
    "\n",
    "segmentor = Segmentor(\n",
    "    min_p=4,\n",
    "    max_p=400,\n",
    "    min_a=1000,\n",
    "    max_a=20000,\n",
    "    suit_x_ratio=2 / 7,\n",
    "    suit_y_ratio=1 / 5,\n",
    ")\n",
    "\n",
    "classifer = Classifier()\n",
    "    \n",
    "st = time.time()\n",
    "results = segmentor.seg(inputImage)\n",
    "en = time.time()\n",
    "print(\"time:\", en - st)\n",
    "\n",
    "print(len(results))\n",
    "\n",
    "inputImageMarked = inputImage.copy()\n",
    "for result in results:\n",
    "    contour = np.array(result['bbox'])\n",
    "    cv2.drawContours(inputImageMarked, [contour], 0, (0, 0, 255), 3)\n",
    "    card_class = classifer.get_class(result['suit'])\n",
    "    cv2.putText(inputImageMarked, card_class, [contour[0]], cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0, 0, 255))\n",
    "    \n",
    "# Encode image as jpg numpy array\n",
    "_, buf = cv2.imencode(\".jpg\", inputImageMarked)\n",
    "# Draw result\n",
    "IPython.display.display(IPython.display.Image(data=buf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d3a346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd43442b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
